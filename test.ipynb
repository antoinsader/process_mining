{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./data/0_log_raw.pkl\")\n",
    "df = df.sort_values([\"case_seq_num\", \"timestamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 11 cases out of 7554 (0.1%)\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values([\"case_seq_num\", \"timestamp\"])\n",
    "cases_before = df[\"case_seq_num\"].nunique()\n",
    "df_fil = df.groupby(\"case_seq_num\").filter(lambda x: len(x) > 2)\n",
    "\n",
    "cases_after = df_fil[\"case_seq_num\"].nunique()\n",
    "dropped = cases_before - cases_after\n",
    "pct_dropped = dropped / cases_before * 100\n",
    "print(f\"Dropped {dropped} cases out of {cases_before} ({pct_dropped:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_activity\n",
       "Completed    7546\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_events = (\n",
    "    df_fil.groupby(\"case_seq_num\")[\"concept_name\"]\n",
    "      .last()\n",
    "      .reset_index(name=\"last_activity\")\n",
    ")\n",
    "last_events[\"last_activity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "\n",
    "# helpers to go from pandas ⇢ event log\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "# discovery, conformance, visualization\n",
    "from pm4py.algo.discovery.inductive import factory as inductive_miner\n",
    "from pm4py.algo.conformance.alignments import factory as align_factory\n",
    "from pm4py.visualization.petrinet import factory as vis_factory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import pandas as pd\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "from pm4py.algo.conformance.alignments.petri_net.algorithm import apply as alignments_apply\n",
    "from pm4py.objects.conversion.log.variants.to_event_log import Parameters\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.algo.discovery.inductive.algorithm import apply as inductive_apply\n",
    "from pm4py.objects.conversion.process_tree.variants.to_petri_net import apply as pt_to_petri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.conformance.alignments.petri_net.algorithm import apply as alignments_apply\n",
    "fitness_A2_on_C = alignments_apply(a_lg, c_net, c_initial_marking, c_final_marking)[0][\"fitness\"]\n",
    "fitness_C_on_A2 = alignments_apply(c_lg,  a_net, a_initial_marking, a_final_marking)[0][\"fitness\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_A2_on_C, fitness_C_on_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.evaluation.precision.algorithm import apply as precision_apply, Variants as PrecisionVariants\n",
    "\n",
    "\n",
    "prec_A2_on_C = precision_apply(\n",
    "    a_lg, c_net, a_initial_marking, a_final_marking,\n",
    "    variant=PrecisionVariants.ETCONFORMANCE_TOKEN\n",
    ")\n",
    "prec_C_on_A2 = precision_apply(\n",
    "    c_lg, a_net, c_initial_marking, c_final_marking,\n",
    "    variant=PrecisionVariants.ETCONFORMANCE_TOKEN\n",
    ")\n",
    "\n",
    "print(f\"Token-based precision A2→C: {prec_A2_on_C:.3f}\")\n",
    "print(f\"Token-based precision C→A2: {prec_C_on_A2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after you have a_net, c_net\n",
    "transitions_A2 = {t.label for t in a_net.transitions if t.label}\n",
    "transitions_C  = {t.label for t in c_net.transitions  if t.label}\n",
    "print(\"Activities in A2 not in C:\", transitions_A2 - transitions_C)\n",
    "print(\"Activities in C not in A2:\", transitions_C  - transitions_A2)\n",
    "print(f\"A2 model: {len(a_net.places)} places, {len(a_net.transitions)} transitions\")\n",
    "print(f\"C  model: {len(c_net.places)} places, {len(c_net.transitions)} transitions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
